{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the national gallery of art open data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/ameya/.cache/kagglehub/datasets/peacehegemony/the-national-gallery-of-art-open-data-program/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"peacehegemony/the-national-gallery-of-art-open-data-program\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path + \"/opendata-main/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining table based on appropriate columns to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108246/2913492502.py:3: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  objects_df = pd.read_csv(path + \"objects.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2886, 47)\n",
      "   objectid  accessioned accessionnum  locationid             title_x   \n",
      "0        61            1    1937.1.54         NaN       The Lacemaker  \\\n",
      "1        62            1    1937.1.55         NaN    The Smiling Girl   \n",
      "2        62            1    1937.1.55         NaN    The Smiling Girl   \n",
      "3      2718            1  1942.9.1839         NaN  Oeuvres poissardes   \n",
      "4        62            1    1937.1.55         NaN    The Smiling Girl   \n",
      "\n",
      "      displaydate  beginyear  endyear visualbrowsertimespan   \n",
      "0         c. 1925     1925.0   1925.0          1901 to 1925  \\\n",
      "1         c. 1925     1925.0   1925.0          1901 to 1925   \n",
      "2         c. 1925     1925.0   1925.0          1901 to 1925   \n",
      "3  published 1796     1796.0   1796.0          1776 to 1800   \n",
      "4         c. 1925     1925.0   1925.0          1901 to 1925   \n",
      "\n",
      "                                   medium  ... language   \n",
      "0                           oil on canvas  ...       en  \\\n",
      "1                           oil on canvas  ...       en   \n",
      "2                           oil on canvas  ...       en   \n",
      "3  1 vol: ill: 4 color stipple engravings  ...       en   \n",
      "4                           oil on canvas  ...       en   \n",
      "\n",
      "                                        thumbnailurl   \n",
      "0  https://www.nga.gov/content/dam/ngaweb/audio-v...  \\\n",
      "1  https://www.nga.gov/content/dam/ngaweb/audio-v...   \n",
      "2  https://www.nga.gov/content/dam/ngaweb/audio-v...   \n",
      "3  https://www.nga.gov/content/dam/ngaweb/audio-v...   \n",
      "4  https://www.nga.gov/content/dam/ngaweb/audio-v...   \n",
      "\n",
      "                                             playurl   \n",
      "0  https://w.soundcloud.com/player/?url=https%3A%...  \\\n",
      "1  https://w.soundcloud.com/player/?url=https%3A%...   \n",
      "2  https://w.soundcloud.com/player/?url=https%3A%...   \n",
      "3  https://w.soundcloud.com/player/?url=https%3A%...   \n",
      "4  https://players.brightcove.net/1191289016001/d...   \n",
      "\n",
      "                                         downloadurl   \n",
      "0  https://api.soundcloud.com/tracks/78345258/dow...  \\\n",
      "1  https://api.soundcloud.com/tracks/78345258/dow...   \n",
      "2  https://api.soundcloud.com/tracks/475697055/do...   \n",
      "3  https://api.soundcloud.com/tracks/475697055/do...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                keywords   \n",
      "0     vermeer, han van meegeren, forgery  \\\n",
      "1     vermeer, han van meegeren, forgery   \n",
      "2  jecmen, rosenwald, prints, drawings,    \n",
      "3  jecmen, rosenwald, prints, drawings,    \n",
      "4  jecmen, rosenwald, prints, drawings,    \n",
      "\n",
      "                                                tags   \n",
      "0  ngaweb:audio-video/audio,ngaweb:audio-video/au...  \\\n",
      "1  ngaweb:audio-video/audio,ngaweb:audio-video/au...   \n",
      "2  ngaweb:constituents/6/2/Constituent_62,ngaweb:...   \n",
      "3  ngaweb:constituents/6/2/Constituent_62,ngaweb:...   \n",
      "4  ngaweb:audio-video/podcast-video,ngaweb:audio-...   \n",
      "\n",
      "                                            imageurl        presentationdate   \n",
      "0  https://www.nga.gov/content/dam/ngaweb/audio-v...  2009-01-11 00:00:00-05  \\\n",
      "1  https://www.nga.gov/content/dam/ngaweb/audio-v...  2009-01-11 00:00:00-05   \n",
      "2  https://www.nga.gov/content/dam/ngaweb/audio-v...  2018-03-16 00:00:00-04   \n",
      "3  https://www.nga.gov/content/dam/ngaweb/audio-v...  2018-03-16 00:00:00-04   \n",
      "4  https://www.nga.gov/content/dam/ngaweb/audio-v...  2018-03-16 00:00:00-04   \n",
      "\n",
      "              releasedate            lastmodified  \n",
      "0  2009-01-20 00:00:00-05  2014-10-10 12:22:21-04  \n",
      "1  2009-01-20 00:00:00-05  2014-10-10 12:22:21-04  \n",
      "2  2018-07-24 00:00:00-04  2019-04-09 15:14:14-04  \n",
      "3  2018-07-24 00:00:00-04  2019-04-09 15:14:14-04  \n",
      "4  2018-07-24 00:00:00-04  2019-04-09 15:14:30-04  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "objects_df = pd.read_csv(path + \"objects.csv\")\n",
    "mediarel_df = pd.read_csv(path + \"media_relationships.csv\")\n",
    "media_items_df = pd.read_csv(path + \"media_items.csv\")\n",
    "\n",
    "obj_mediarel_df = objects_df.merge(\n",
    "    mediarel_df, \n",
    "    left_on=\"objectid\",      \n",
    "    right_on=\"relatedid\",   \n",
    "    how=\"inner\"             \n",
    ")\n",
    "\n",
    "merged_df = obj_mediarel_df.merge(\n",
    "    media_items_df,\n",
    "    on=\"mediaid\",            \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dictionary with objectid as the key and related imageurls as the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807\n"
     ]
    }
   ],
   "source": [
    "images_dict = {}\n",
    "\n",
    "for idx, row in merged_df.iterrows():\n",
    "    obj_id = row[\"objectid\"]\n",
    "    img_path = row[\"imageurl\"]  \n",
    "\n",
    "    if obj_id not in images_dict:\n",
    "        images_dict[obj_id] = []\n",
    "    \n",
    "    images_dict[obj_id].append(img_path)\n",
    "\n",
    "# test_ids = list(images_dict.keys())\n",
    "# for test_id in test_ids:\n",
    "#     print(f\"Object ID: {test_id}\")\n",
    "#     print(\"Image paths:\", images_dict[test_id])\n",
    "print(len(images_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading image from the given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = 0\n",
    "total = 0\n",
    "def load_image_from_url(url):\n",
    "    global issues, total\n",
    "    try:\n",
    "        total += 1\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        issues += 1\n",
    "        return Image.new(\"RGB\", (224, 224), (0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset for siamese networks (consisting of negative and positive samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, images_dict, transform=None, target_size=(224, 224)):\n",
    "        self.images_dict = images_dict\n",
    "        self.object_ids = list(images_dict.keys())\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.pairs = []\n",
    "        self.labels = []\n",
    "        self._create_pairs()\n",
    "\n",
    "    def _create_pairs(self):\n",
    "        for obj_id in self.object_ids:\n",
    "            urls = self.images_dict[obj_id]\n",
    "            if len(urls) < 2:\n",
    "                continue\n",
    "            for i in range(len(urls)):\n",
    "                for j in range(i+1, len(urls)):\n",
    "                    self.pairs.append((urls[i], urls[j]))\n",
    "                    self.labels.append(1)  \n",
    "\n",
    "        num_positive = len(self.labels)\n",
    "        neg_pairs = 0\n",
    "        while neg_pairs < num_positive:\n",
    "            id1, id2 = random.sample(self.object_ids, 2)\n",
    "            if len(self.images_dict[id1]) == 0 or len(self.images_dict[id2]) == 0:\n",
    "                continue\n",
    "            url1 = random.choice(self.images_dict[id1])\n",
    "            url2 = random.choice(self.images_dict[id2])\n",
    "            self.pairs.append((url1, url2))\n",
    "            self.labels.append(0)  \n",
    "            neg_pairs += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        url1, url2 = self.pairs[idx]\n",
    "        img1 = load_image_from_url(url1)\n",
    "        img2 = load_image_from_url(url2)\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return img1, img2, label    \n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SiameseDataset(images_dict, transform=transform)\n",
    "# split into test and train\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)                              \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive loss function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            label * torch.pow(euclidean_distance, 2) +\n",
    "            (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11 - Training:   0%|          | 0/742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/11], Loss: 0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/11], Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/11], Loss: 0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/11], Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/11], Loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/11], Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/11], Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Wrap the training dataloader with tqdm directly\u001b[39;00m\n\u001b[1;32m      7\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img1, img2, label \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[1;32m      9\u001b[0m     img1, img2, label \u001b[38;5;241m=\u001b[39m img1\u001b[38;5;241m.\u001b[39mto(device), img2\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1420\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1420\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 11\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=False)\n",
    "    for img1, img2, label in train_bar:\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(img1, img2)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_bar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, label in test_bar:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            test_loss += loss.item()\n",
    "            test_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    if(epoch % 5 == 0):\n",
    "        torch.save(model.state_dict(), f\"siamese_model_epoch{epoch}.pt\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation (consisting of anchor, positive and negative images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, images_dict, transform=None, target_size=(224, 224)):\n",
    "        self.images_dict = images_dict\n",
    "        self.object_ids = list(images_dict.keys())\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.all_images = [(obj_id, url) for obj_id, urls in images_dict.items() for url in urls]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_obj_id, anchor_url = self.all_images[idx]\n",
    "        anchor_img = load_image_from_url(anchor_url)\n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "\n",
    "        positive_urls = self.images_dict[anchor_obj_id]\n",
    "        if len(positive_urls) < 2:\n",
    "            positive_img = anchor_img.clone()\n",
    "        else:\n",
    "            candidate_urls = [url for url in positive_urls if url != anchor_url]\n",
    "            if candidate_urls:\n",
    "                pos_url = random.choice(candidate_urls)\n",
    "            else:\n",
    "                pos_url = anchor_url\n",
    "            positive_img = load_image_from_url(pos_url)\n",
    "            if self.transform:\n",
    "                positive_img = self.transform(positive_img)\n",
    "\n",
    "        negative_obj_id = random.choice([oid for oid in self.object_ids if oid != anchor_obj_id])\n",
    "        neg_url = random.choice(self.images_dict[negative_obj_id])\n",
    "        negative_img = load_image_from_url(neg_url)\n",
    "        if self.transform:\n",
    "            negative_img = self.transform(negative_img)\n",
    "\n",
    "        return anchor_img, positive_img, negative_img\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_dataset = TripletDataset(images_dict, transform=transform)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_size = int(0.8 * len(triplet_dataset))\n",
    "test_size = len(triplet_dataset) - train_size\n",
    "triplet_train_dataset, triplet_test_dataset = torch.utils.data.random_split(triplet_dataset, [train_size, test_size])\n",
    "triplet_train_loader = DataLoader(triplet_train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "triplet_test_loader = DataLoader(triplet_test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)                              \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeatureExtractor().to(device)\n",
    "margin = 1.0\n",
    "criterion = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model with triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11: 100%|██████████| 145/145 [08:12<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/11], Loss: 0.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/11 - Testing: 100%|██████████| 37/37 [01:43<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11: 100%|██████████| 145/145 [05:28<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/11], Loss: 0.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/11 - Testing: 100%|██████████| 37/37 [01:19<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11: 100%|██████████| 145/145 [04:37<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/11], Loss: 0.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/11 - Testing: 100%|██████████| 37/37 [01:08<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11: 100%|██████████| 145/145 [04:24<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/11], Loss: 0.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/11 - Testing: 100%|██████████| 37/37 [01:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11: 100%|██████████| 145/145 [04:29<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/11], Loss: 0.5368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/11 - Testing: 100%|██████████| 37/37 [01:10<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11: 100%|██████████| 145/145 [04:31<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/11], Loss: 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/11 - Testing: 100%|██████████| 37/37 [01:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11: 100%|██████████| 145/145 [04:02<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/11], Loss: 0.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/11 - Testing: 100%|██████████| 37/37 [01:03<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11: 100%|██████████| 145/145 [04:15<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/11], Loss: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/11 - Testing: 100%|██████████| 37/37 [01:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11: 100%|██████████| 145/145 [04:03<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/11], Loss: 0.3199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/11 - Testing: 100%|██████████| 37/37 [01:04<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11: 100%|██████████| 145/145 [04:07<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/11], Loss: 0.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/11 - Testing: 100%|██████████| 37/37 [01:02<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11: 100%|██████████| 145/145 [04:19<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/11], Loss: 0.2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/11 - Testing: 100%|██████████| 37/37 [01:12<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2251\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 11\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(tqdm(triplet_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute embeddings\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "\n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(triplet_train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    if(epoch % 5 == 0):\n",
    "        torch.save(model.state_dict(), f\"triplet_model_epoch{epoch}.pt\")\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative in tqdm(triplet_test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\"):\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(triplet_test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = FeatureExtractor().to(device)\n",
    "model1.load_state_dict(torch.load(\"triplet_model_epoch10.pt\"))\n",
    "\n",
    "model2 = SiameseNetwork().to(device)\n",
    "model2.load_state_dict(torch.load(\"siamese_model_epoch5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [07:09<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity for Positive Pairs: 0.9815\n",
      "Average Cosine Similarity for Negative Pairs: 0.2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Using the validation set to test the models\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings1 = []\n",
    "    embeddings2 = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, label in tqdm(dataloader):\n",
    "            img1, img2 = img1.to(device), img2.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            embeddings1.append(output1)\n",
    "            embeddings2.append(output2)\n",
    "            labels.append(label)\n",
    "    embeddings1 = torch.cat(embeddings1)\n",
    "    embeddings2 = torch.cat(embeddings2)\n",
    "    labels = torch.cat(labels)\n",
    "    return embeddings1, embeddings2, labels\n",
    "\n",
    "siamese_embeddings1, siamese_embeddings2, siamese_labels = evaluate_model(model2, test_loader)\n",
    "\n",
    "## Calculate the average cosine similarity for positive and negative pairs respectively\n",
    "def calculate_cosine_similarity(embeddings1, embeddings2):\n",
    "    cosine_similarity = nn.CosineSimilarity(dim=1)\n",
    "    return cosine_similarity(embeddings1, embeddings2)\n",
    "\n",
    "positive_indices = siamese_labels == 1\n",
    "negative_indices = siamese_labels == 0\n",
    "\n",
    "positive_similarities = calculate_cosine_similarity(siamese_embeddings1[positive_indices], siamese_embeddings2[positive_indices])\n",
    "negative_similarities = calculate_cosine_similarity(siamese_embeddings1[negative_indices], siamese_embeddings2[negative_indices])\n",
    "\n",
    "print(f\"Average Cosine Similarity for Positive Pairs: {positive_similarities.mean().item():.4f}\")\n",
    "print(f\"Average Cosine Similarity for Negative Pairs: {negative_similarities.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:58<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity (Anchor-Positive, Similar): 0.7788\n",
      "Average Cosine Similarity (Anchor-Negative, Dissimilar): 0.2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities_similar = []\n",
    "cosine_similarities_dissimilar = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for anchor, positive, negative in tqdm(triplet_test_loader):\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        anchor_out = model1(anchor)\n",
    "        positive_out = model1(positive)\n",
    "        negative_out = model1(negative)\n",
    "        \n",
    "        cos_sim_similar = F.cosine_similarity(anchor_out, positive_out, dim=1)\n",
    "        cos_sim_dissimilar = F.cosine_similarity(anchor_out, negative_out, dim=1)\n",
    "        \n",
    "        cosine_similarities_similar.append(cos_sim_similar)\n",
    "        cosine_similarities_dissimilar.append(cos_sim_dissimilar)\n",
    "\n",
    "avg_cos_sim_similar = torch.cat(cosine_similarities_similar).mean().item()\n",
    "avg_cos_sim_dissimilar = torch.cat(cosine_similarities_dissimilar).mean().item()\n",
    "\n",
    "print(f\"Average Cosine Similarity (Anchor-Positive, Similar): {avg_cos_sim_similar:.4f}\")\n",
    "print(f\"Average Cosine Similarity (Anchor-Negative, Dissimilar): {avg_cos_sim_dissimilar:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
