{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mameyar3103\u001b[0m (\u001b[33mameyar3103-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ameya/Pictures/ArtExtractTestTaskGSoC/wandb/run-20250318_130856-yt9m4y42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art/runs/yt9m4y42' target=\"_blank\">dauntless-eon-9</a></strong> to <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art' target=\"_blank\">https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art/runs/yt9m4y42' target=\"_blank\">https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art/runs/yt9m4y42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art/runs/yt9m4y42?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x744d1b98cf40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"ameyar3103-iiit-hyderabad\",project=\"recurrent_conv_art\", config={\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"model\": \"RecurrentCNN\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('wikiart_csv/genre_train.csv',header=None, names=[\"image_path\", \"genre_id\"])\n",
    "df_val = pd.read_csv('wikiart_csv/genre_val.csv',header=None, names=[\"image_path\", \"genre_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of classes\n",
    "num_classes = 10 # from genre_class.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather input data\n",
    "train_images = df_train['image_path'].values\n",
    "train_labels = df_train['genre_id'].values\n",
    "\n",
    "val_images = df_val['image_path'].values\n",
    "val_labels = df_val['genre_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data and create test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Impressionism/robert-julian-onderdonk_goat-herder-at-the-san-antonio-quarry-1909.jpg', 'Impressionism/arthur-verona_neagoe-basarab-study.jpg', 'Early_Renaissance/paolo-uccello_st-francis.jpg', 'High_Renaissance/michelangelo_the-ancestors-of-christ-manasseh-amon-1512.jpg', 'Baroque/adriaen-brouwer_inn-with-drunken-peasants.jpg', 'Realism/vincent-van-gogh_farmhouses-in-loosduinen-near-the-hague-at-twilight-1883(1).jpg', 'Romanticism/jan-matejko_jadwiga.jpg', 'Post_Impressionism/bertalan-por_brookside-1919.jpg', 'Realism/ivan-shishkin_fir.jpg', 'Impressionism/camille-pissarro_landscape-with-a-man-digging-1877.jpg', 'Romanticism/dante-gabriel-rossetti_study-for-a-vision-of-fiammetta.jpg', 'Expressionism/martiros-saryan_gohtan-mountains-1914.jpg', 'Realism/vasily-vereshchagin_parsi-priest-fire-worshiper-bombay-1876.jpg', 'Realism/klavdy-lebedev_spat-on-the-terrace.jpg', 'Impressionism/pierre-auguste-renoir_young-girl-in-a-flowered-hat-1905.jpg', 'Realism/johan-hendrik-weissenbruch_figures-on-a-country-road-a-church-in-the-distance.jpg', 'Minimalism/genevieve-asse_blue-depth-1978.jpg', 'High_Renaissance/vittore-carpaccio_the-glory-of-st-vidal-1514.jpg', 'Cubism/paul-klee_senecio-1922(1).jpg', 'Cubism/georges-braque_big-nude-1908.jpg', 'Art_Nouveau_Modern/ivan-bilibin_illustration-for-the-poem-the-tale-of-the-golden-cockerel-by-alexander-pushkin-1906-2(1).jpg', 'Romanticism/homer-watson_old-mill-and-stream-1879.jpg', 'Romanticism/gustave-dore_don-quixote-58.jpg', 'Realism/charles-francois-daubigny_castle-gaillard-in-andelys-eure-1877.jpg', 'Impressionism/nikolay-bogdanov-belsky_children.jpg', 'Romanticism/gustave-dore_don-quixote-55.jpg', 'Color_Field_Painting/theodoros-stamos_olympia-sun-box-1957.jpg', 'Realism/vasily-polenov_right-hand-keeping-the-staff.jpg', 'Mannerism_Late_Renaissance/correggio_the-assumption-of-the-virgin-detail-1530(3).jpg', 'Impressionism/william-merritt-chase_peonies.jpg', 'High_Renaissance/andrea-del-sarto_portrait-of-baccio-bandinelli.jpg', 'New_Realism/george-luks_the-wrestlers-1905.jpg', 'Pop_Art/edward-ruscha_standard-station-1966.jpg', 'Northern_Renaissance/mabuse_madonna-and-child-playing-with-the-veil.jpg', 'Impressionism/william-james-glackens_lenna-painting-the-artist-s-daughter-1918.jpg', 'Expressionism/pablo-picasso_portrait-of-madame-patri-1918.jpg', 'Symbolism/nicholas-roerich_monhigan-study-1922-14.jpg', 'Realism/ilya-repin_in-the-hut-1895.jpg', 'Post_Impressionism/pierre-bonnard_view-of-le-cannet-roofs-1942.jpg', 'Symbolism/mstislav-dobuzhinsky_vilno-street-1906(1).jpg', 'Impressionism/berthe-morisot_the-sewing-lesson-aka-the-artist-s-daughter-julie-with-her-nanny.jpg', 'Impressionism/ipolit-strambu_nude-with-carpet-background-1921.jpg', 'Post_Impressionism/salvador-dali_the-garden-at-lyane.jpg', 'Realism/pyotr-konchalovsky_conductor-nikolai-semenovich-golovanov-and-orchestra-1934.jpg', 'Art_Nouveau_Modern/boris-kustodiev_illustration-for-nikolay-nekrasov-poem-uncle-jacob-1921.jpg', 'Realism/vincent-van-gogh_peasant-woman-with-shawl-over-her-head-seen-from-the-side-2-1885.jpg', 'Expressionism/lucian-freud_girl-in-a-fur-coat-1967.jpg', 'Fauvism/maurice-de-vlaminck_sailboats-at-chatou.jpg', 'Post_Impressionism/vincent-van-gogh_sheet-with-sketches-of-working-people-1890-1.jpg', 'Post_Impressionism/gustave-loiseau_trees-in-bloom.jpg', 'Rococo/vladimir-borovikovsky_portrait-of-the-artist-dmitry-levitzky-1796.jpg', 'High_Renaissance/giovanni-bellini_st-jerome-st-christopher-and-st-augustine-1513.jpg', 'Expressionism/dimitris-mytaras_female-figures.jpg', 'Impressionism/eugene-boudin_the-beach-at-trouville.jpg', 'Realism/robert-brackman_a-plate-of-fruit.jpg', 'Impressionism/joaqu√£\\xadn-sorolla_chumberas-study.jpg', 'Romanticism/jean-leon-gerome_a-japanese-imploring-a-divinity.jpg', 'Realism/gustave-courbet_the-hallali-1869.jpg', 'Realism/gustave-courbet_the-source-of-the-loue-1864.jpg', 'Baroque/joseph-wright_mrs-john-ashton.jpg', 'Abstract_Expressionism/sam-francis_pioggia-d-oro-golden-rain-1988.jpg', 'Expressionism/martiros-saryan_landscape-with-mountains-1929.jpg', 'Art_Nouveau_Modern/alphonse-mucha_maude-adams-as-joan-of-arc-1909.jpg', 'Impressionism/fern-coppedge_old-house-point-pleasant.jpg')\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# create test and train dataset for dataloader\n",
    "\n",
    "def get_image(image_path,image_size=224):\n",
    "    try:\n",
    "        img = cv2.imread('./wikiart/' + image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image not loaded: ./wikiart/{image_path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        scale = 256 / min(h, w)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        img_resized = cv2.resize(img, (new_w, new_h))\n",
    "        start_x = (new_w - image_size) // 2\n",
    "        start_y = (new_h - image_size) // 2\n",
    "        img_cropped = img_resized[start_y:start_y+image_size, start_x:start_x+image_size]\n",
    "        img_cropped = img_cropped.astype(np.float32) / 255.0\n",
    "        img_tensor = torch.from_numpy(img_cropped).permute(2, 0, 1)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img_tensor = (img_tensor - mean) / std\n",
    "        return img_tensor\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return torch.zeros(3, image_size, image_size)\n",
    "\n",
    "class WikiArtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image_vectors = []\n",
    "        # for image in self.images:\n",
    "        #     image_emb = get_image(image)\n",
    "        #     image_vectors.append(image_emb)\n",
    "        # image = torch.stack(image_vectors)\n",
    "        image = self.images[idx]\n",
    "        # label should be a one-hot encoded vector\n",
    "        label = torch.zeros(num_classes)\n",
    "        label[self.labels[idx]] = 1\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_dataset = WikiArtDataset(train_images, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = WikiArtDataset(val_images, val_labels)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(images)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RecurrentCNN(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden_size=256, dropout_prob=0.5):\n",
    "        super(RecurrentCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((14, 56))\n",
    "        self.lstm_input_size = 64 * 56\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=lstm_hidden_size,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(2 * lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))      \n",
    "        x = self.pool1(x)              \n",
    "        x = F.relu(self.conv2(x))      \n",
    "        x = self.pool2(x)              \n",
    "        x = self.adaptive_pool(x)      \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  \n",
    "        batch_size, seq_len, channels, width = x.shape  \n",
    "        x = x.view(batch_size, seq_len, channels * width)  \n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "        x = lstm_out.mean(dim=1)    \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = RecurrentCNN(num_classes)\n",
    "model.to('cuda')\n",
    "\n",
    "# Loss and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "wandb.watch(model, log=\"all\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 374/711 [06:07<05:21,  1.05it/s, loss=1.49]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 1/20:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 696/711 [11:19<00:12,  1.16it/s, loss=1.68]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:34<00:00,  1.02it/s, loss=1.7] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:29<00:00,  1.13it/s, loss=1.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.6431, Val Loss: 1.4642, Val Accuracy: 49.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 438/711 [07:15<03:51,  1.18it/s, loss=1.45]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 2/20:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 512/711 [08:25<03:08,  1.06it/s, loss=1.74]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:41<00:00,  1.01it/s, loss=1.34]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:35<00:00,  1.11it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 1.4466, Val Loss: 1.4048, Val Accuracy: 50.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:  26%|‚ñà‚ñà‚ñå       | 185/711 [03:08<08:27,  1.04it/s, loss=1.22]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 3/20:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 385/711 [06:19<04:57,  1.10it/s, loss=1.48]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:28<00:00,  1.03it/s, loss=1.43] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:28<00:00,  1.14it/s, loss=1.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 1.3456, Val Loss: 1.3164, Val Accuracy: 54.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 463/711 [07:16<04:06,  1.01it/s, loss=1.2]  Corrupt JPEG data: bad Huffman code\n",
      "Epoch 4/20:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 591/711 [09:19<01:47,  1.11it/s, loss=1.46] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:16<00:00,  1.05it/s, loss=1.2]  \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:26<00:00,  1.14it/s, loss=1.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 1.2404, Val Loss: 1.2897, Val Accuracy: 55.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20:  31%|‚ñà‚ñà‚ñà       | 217/711 [03:24<08:41,  1.06s/it, loss=0.926]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 5/20:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 336/711 [05:20<05:55,  1.06it/s, loss=1.44] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:17<00:00,  1.05it/s, loss=1.04] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:28<00:00,  1.14it/s, loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 1.1248, Val Loss: 1.2582, Val Accuracy: 56.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:  31%|‚ñà‚ñà‚ñà       | 218/711 [03:27<07:56,  1.03it/s, loss=0.926]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 6/20:  35%|‚ñà‚ñà‚ñà‚ñç      | 246/711 [03:54<07:28,  1.04it/s, loss=0.839]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:14<00:00,  1.05it/s, loss=1.03] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:26<00:00,  1.15it/s, loss=1.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.9760, Val Loss: 1.2952, Val Accuracy: 56.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 305/711 [04:49<06:21,  1.06it/s, loss=0.529]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 7/20:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 399/711 [06:17<04:40,  1.11it/s, loss=0.841]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [11:12<00:00,  1.06it/s, loss=0.709]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 305/305 [04:29<00:00,  1.13it/s, loss=1.55] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.7983, Val Loss: 1.3486, Val Accuracy: 56.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20:   0%|          | 3/711 [00:03<12:03,  1.02s/it, loss=0.813]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 8/20:  38%|‚ñà‚ñà‚ñà‚ñä      | 269/711 [04:20<07:08,  1.03it/s, loss=0.511]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_paths, labels \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m----> 9\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([get_image(image_path) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths])\n\u001b[1;32m     10\u001b[0m     images \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_paths, labels \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m----> 9\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths])\n\u001b[1;32m     10\u001b[0m     images \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mget_image\u001b[0;34m(image_path, image_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image\u001b[39m(image_path,image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./wikiart/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not loaded: ./wikiart/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x744d1bc5e4d0>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:769\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for image_paths, labels in train_bar:\n",
    "        image_tensors = torch.stack([get_image(image_path) for image_path in image_paths])\n",
    "        images = image_tensors.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    wandb.log({\"epoch\": epoch+1, \"train_loss\": avg_train_loss})\n",
    "    \n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        for image_paths, labels in val_bar:\n",
    "            image_tensors = torch.stack([get_image(image_path) for image_path in image_paths])\n",
    "            image_tensors = image_tensors.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            outputs = model(image_tensors)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    wandb.log({\"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy})\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    if(epoch%5==0):\n",
    "        torch.save(model.state_dict(), f\"recurrent_cnn_epoch_{epoch}_genre.pth\")\n",
    "        torch.save(optimizer.state_dict(), f\"recurrent_cnn_optimizer_epoch_{epoch}_genre.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
