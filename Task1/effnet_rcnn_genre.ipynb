{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mameyar3103\u001b[0m (\u001b[33mameyar3103-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ameya/Pictures/ArtExtractTestTaskGSoC/wandb/run-20250318_150548-y189tbs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet/runs/y189tbs6' target=\"_blank\">misty-dawn-2</a></strong> to <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet' target=\"_blank\">https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet/runs/y189tbs6' target=\"_blank\">https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet/runs/y189tbs6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ameyar3103-iiit-hyderabad/recurrent_conv_art_effnet/runs/y189tbs6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7e8191cc1390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"ameyar3103-iiit-hyderabad\",project=\"recurrent_conv_art_effnet\", config={\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"model\": \"EFFNET_RCNN\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('wikiart_csv/genre_train.csv',header=None, names=[\"image_path\", \"genre_id\"])\n",
    "df_val = pd.read_csv('wikiart_csv/genre_val.csv',header=None, names=[\"image_path\", \"genre_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of classes\n",
    "num_classes = 10 # from artist_class.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather input data\n",
    "train_images = df_train['image_path'].values\n",
    "train_labels = df_train['genre_id'].values\n",
    "\n",
    "val_images = df_val['image_path'].values\n",
    "val_labels = df_val['genre_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data and create test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Impressionism/claude-monet_small-boat-on-the-small-branch-of-the-seine-at-argenteuil.jpg', 'Art_Nouveau_Modern/raphael-kirchner_lillian-lorraine.jpg', 'Abstract_Expressionism/conrad-marca-relli_untitled-1958.jpg', 'Naive_Art_Primitivism/marc-chagall_lovers.jpg', 'Rococo/bernardo-bellotto_the-kreuzkirche-in-dresden.jpg', 'High_Renaissance/michelangelo_the-prophet-daniel-1511.jpg', 'High_Renaissance/pietro-perugino_pala-di-monteripido.jpg', 'Symbolism/nicholas-roerich_and-we-are-opening-the-gates-1922.jpg', 'Impressionism/claude-monet_vetheuil-afternoon.jpg', 'Romanticism/francisco-goya_the-repentant-saint-peter.jpg', 'Realism/edgar-degas_portrait-of-rene-de-gas-1855.jpg', 'Realism/camille-corot_dieppe-end-of-a-pier-and-the-sea-1822.jpg', 'Romanticism/orest-kiprensky_peasant-boy-1814.jpg', 'Expressionism/richard-gerstl_small-street-nu-dorferstra-e-1908.jpg', 'Abstract_Expressionism/rafa-nasiri_untitled-068-2002.jpg', 'Romanticism/gheorghe-tattarescu_laz-r-kalinderu.jpg', 'Realism/ivan-shishkin_countess-mordvinov-s-forest-1891.jpg', 'Baroque/jan-steen_twelfth-night-1668.jpg', 'Realism/salvador-dali_cathedral-unfinished.jpg', 'Northern_Renaissance/pieter-bruegel-the-elder_the-fair-at-hoboken-1559.jpg', 'Impressionism/claude-monet_palazzo-contarini-2.jpg', 'Abstract_Expressionism/brice-marden_dragons-2004.jpg', 'Post_Impressionism/henri-de-toulouse-lautrec_girl-in-a-fur-mademoiselle-jeanne-fontaine-1891.jpg', 'Color_Field_Painting/john-hoyland_22-8-74-1974.jpg', 'Expressionism/oskar-kokoschka_not_detected_235843.jpg', 'Impressionism/pierre-auguste-renoir_the-first-outing-1876.jpg', 'Expressionism/nicolae-tonitza_morning-at-balcic.jpg', 'Baroque/jan-steen_prayer-before-meal-1660.jpg', 'Realism/ivan-shishkin_among-the-open-valley-1883.jpg', 'Baroque/anthony-van-dyck_margareta-snyders.jpg', 'Ukiyo_e/kitagawa-utamaro_a-woman-watches-two-children.jpg', 'New_Realism/edward-hopper_untitled.jpg')\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def get_image(image_path,image_size=224):\n",
    "    try:\n",
    "        img = cv2.imread('./wikiart/' + image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image not loaded: ./wikiart/{image_path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        scale = 256 / min(h, w)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        img_resized = cv2.resize(img, (new_w, new_h))\n",
    "        start_x = (new_w - image_size) // 2\n",
    "        start_y = (new_h - image_size) // 2\n",
    "        img_cropped = img_resized[start_y:start_y+image_size, start_x:start_x+image_size]\n",
    "        img_cropped = img_cropped.astype(np.float32) / 255.0\n",
    "        img_tensor = torch.from_numpy(img_cropped).permute(2, 0, 1)\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img_tensor = (img_tensor - mean) / std\n",
    "        return img_tensor\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return torch.zeros(3, image_size, image_size)\n",
    "\n",
    "class WikiArtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image_vectors = []\n",
    "        # for image in self.images:\n",
    "        #     image_emb = get_image(image)\n",
    "        #     image_vectors.append(image_emb)\n",
    "        # image = torch.stack(image_vectors)\n",
    "        image = self.images[idx]\n",
    "        # label should be a one-hot encoded vector\n",
    "        label = torch.zeros(num_classes)\n",
    "        label[self.labels[idx]] = 1\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_dataset = WikiArtDataset(train_images, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = WikiArtDataset(val_images, val_labels)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(images)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "class EffNetLSTM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # EfficientNet-B0 backbone (outputs 1280 channels)\n",
    "        effnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        self.cnn = effnet.features  \n",
    "        \n",
    "        self.channel_reducer = nn.Sequential(\n",
    "            nn.Conv2d(1280, 512, kernel_size=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)  \n",
    "        \n",
    "        x = self.channel_reducer(features)  \n",
    "        bs, c, h, w = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).reshape(bs, h*w, c)  \n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        last_hidden = torch.cat((h_n[-2], h_n[-1]), dim=1)  \n",
    "        \n",
    "        return self.classifier(last_hidden)\n",
    "    \n",
    "model = EffNetLSTM(num_classes)\n",
    "model.to('cuda')\n",
    "\n",
    "# Loss and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "wandb.watch(model, log=\"all\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.cnn.parameters(), 'lr': 1e-5},\n",
    "    {'params': model.channel_reducer.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.lstm.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:  58%|█████▊    | 824/1422 [08:56<07:01,  1.42it/s, loss=1.18] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 1/20:  82%|████████▏ | 1164/1422 [12:35<02:51,  1.51it/s, loss=1.35] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 1/20: 100%|██████████| 1422/1422 [15:20<00:00,  1.54it/s, loss=1.03] \n",
      "Validation: 100%|██████████| 610/610 [04:51<00:00,  2.09it/s, loss=0.6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.1836, Val Loss: 0.8882, Val Accuracy: 70.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:  56%|█████▌    | 791/1422 [08:29<08:09,  1.29it/s, loss=1.07] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 2/20:  97%|█████████▋| 1386/1422 [14:49<00:21,  1.69it/s, loss=0.583]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 2/20: 100%|██████████| 1422/1422 [15:11<00:00,  1.56it/s, loss=0.774]\n",
      "Validation: 100%|██████████| 610/610 [04:49<00:00,  2.11it/s, loss=0.204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.8713, Val Loss: 0.7987, Val Accuracy: 72.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:  10%|█         | 148/1422 [01:31<13:01,  1.63it/s, loss=0.905]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 3/20:  30%|██▉       | 424/1422 [04:28<10:34,  1.57it/s, loss=0.983]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 3/20: 100%|██████████| 1422/1422 [15:05<00:00,  1.57it/s, loss=0.523]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.157] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.7778, Val Loss: 0.7656, Val Accuracy: 73.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:  38%|███▊      | 537/1422 [05:42<10:12,  1.45it/s, loss=0.44] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 4/20:  69%|██████▉   | 978/1422 [10:22<04:53,  1.51it/s, loss=1.04] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 4/20: 100%|██████████| 1422/1422 [15:07<00:00,  1.57it/s, loss=0.917]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.7073, Val Loss: 0.7555, Val Accuracy: 74.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20:  57%|█████▋    | 812/1422 [08:41<07:30,  1.35it/s, loss=1.04] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 5/20:  79%|███████▉  | 1121/1422 [11:55<03:11,  1.57it/s, loss=0.732]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 5/20: 100%|██████████| 1422/1422 [15:08<00:00,  1.56it/s, loss=0.52] \n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.6479, Val Loss: 0.7431, Val Accuracy: 74.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:   6%|▌         | 80/1422 [00:52<17:43,  1.26it/s, loss=0.683]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 6/20:  18%|█▊        | 251/1422 [02:39<11:19,  1.72it/s, loss=0.924]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 6/20: 100%|██████████| 1422/1422 [15:08<00:00,  1.57it/s, loss=0.751]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.0644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.5945, Val Loss: 0.7447, Val Accuracy: 74.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:   6%|▌         | 84/1422 [00:53<15:58,  1.40it/s, loss=0.664]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 7/20:  54%|█████▍    | 768/1422 [08:06<07:09,  1.52it/s, loss=0.575]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 7/20: 100%|██████████| 1422/1422 [15:08<00:00,  1.57it/s, loss=0.173]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.0354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.5459, Val Loss: 0.7553, Val Accuracy: 74.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20:  34%|███▍      | 484/1422 [05:00<09:12,  1.70it/s, loss=0.48] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 8/20:  77%|███████▋  | 1094/1422 [11:34<03:16,  1.67it/s, loss=0.685]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 8/20: 100%|██████████| 1422/1422 [15:06<00:00,  1.57it/s, loss=0.312]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.4907, Val Loss: 0.7706, Val Accuracy: 74.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20:  15%|█▍        | 211/1422 [02:12<12:17,  1.64it/s, loss=0.241]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 9/20:  24%|██▎       | 335/1422 [03:30<11:42,  1.55it/s, loss=0.69] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 9/20: 100%|██████████| 1422/1422 [15:04<00:00,  1.57it/s, loss=0.492]\n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.4510, Val Loss: 0.7911, Val Accuracy: 75.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20:   2%|▏         | 24/1422 [00:14<14:36,  1.59it/s, loss=0.443]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 10/20:  82%|████████▏ | 1171/1422 [12:23<02:49,  1.48it/s, loss=0.485]Corrupt JPEG data: bad Huffman code\n",
      "Epoch 10/20: 100%|██████████| 1422/1422 [15:05<00:00,  1.57it/s, loss=0.174] \n",
      "Validation: 100%|██████████| 610/610 [04:49<00:00,  2.11it/s, loss=0.0766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.4041, Val Loss: 0.8214, Val Accuracy: 74.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20:   3%|▎         | 48/1422 [00:30<16:54,  1.35it/s, loss=0.299]Corrupt JPEG data: premature end of data segment\n",
      "Epoch 11/20:  72%|███████▏  | 1019/1422 [10:47<04:36,  1.46it/s, loss=0.76] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 11/20: 100%|██████████| 1422/1422 [15:06<00:00,  1.57it/s, loss=0.26]  \n",
      "Validation: 100%|██████████| 610/610 [04:50<00:00,  2.10it/s, loss=0.0493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.3686, Val Loss: 0.8205, Val Accuracy: 74.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:  56%|█████▌    | 796/1422 [08:31<06:17,  1.66it/s, loss=0.481] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 12/20:  86%|████████▋ | 1228/1422 [13:06<02:02,  1.58it/s, loss=0.218] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 12/20: 100%|██████████| 1422/1422 [15:08<00:00,  1.57it/s, loss=0.485] \n",
      "Validation: 100%|██████████| 610/610 [04:51<00:00,  2.09it/s, loss=0.00808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.3261, Val Loss: 0.8793, Val Accuracy: 74.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20:  13%|█▎        | 179/1422 [01:53<14:04,  1.47it/s, loss=0.106] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 13/20:  29%|██▉       | 419/1422 [04:24<11:09,  1.50it/s, loss=0.545] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 13/20: 100%|██████████| 1422/1422 [15:05<00:00,  1.57it/s, loss=0.205] \n",
      "Validation: 100%|██████████| 610/610 [04:48<00:00,  2.11it/s, loss=0.024] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.2988, Val Loss: 0.8529, Val Accuracy: 75.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20:  23%|██▎       | 328/1422 [03:25<11:18,  1.61it/s, loss=0.1]   Corrupt JPEG data: bad Huffman code\n",
      "Epoch 14/20:  35%|███▌      | 500/1422 [05:15<11:12,  1.37it/s, loss=0.261] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 14/20: 100%|██████████| 1422/1422 [15:06<00:00,  1.57it/s, loss=0.174] \n",
      "Validation: 100%|██████████| 610/610 [04:49<00:00,  2.10it/s, loss=0.00185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train Loss: 0.2672, Val Loss: 0.9576, Val Accuracy: 74.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20:  55%|█████▍    | 781/1422 [08:12<06:12,  1.72it/s, loss=0.558] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 15/20:  68%|██████▊   | 966/1422 [10:12<05:05,  1.49it/s, loss=0.226] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 15/20: 100%|██████████| 1422/1422 [15:07<00:00,  1.57it/s, loss=0.364] \n",
      "Validation: 100%|██████████| 610/610 [04:49<00:00,  2.11it/s, loss=0.00409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.2376, Val Loss: 0.9952, Val Accuracy: 74.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20:  49%|████▉     | 694/1422 [07:24<08:46,  1.38it/s, loss=0.245] Corrupt JPEG data: premature end of data segment\n",
      "Epoch 16/20:  81%|████████  | 1147/1422 [12:10<03:21,  1.37it/s, loss=0.103] Corrupt JPEG data: bad Huffman code\n",
      "Epoch 16/20: 100%|██████████| 1422/1422 [15:04<00:00,  1.57it/s, loss=0.234] \n",
      "Validation:  33%|███▎      | 204/610 [01:51<03:41,  1.83it/s, loss=1.56] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m val_bar \u001b[38;5;241m=\u001b[39m tqdm(val_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_paths, labels \u001b[38;5;129;01min\u001b[39;00m val_bar:\n\u001b[0;32m---> 36\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([get_image(image_path) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths])\n\u001b[1;32m     37\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m val_bar \u001b[38;5;241m=\u001b[39m tqdm(val_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_paths, labels \u001b[38;5;129;01min\u001b[39;00m val_bar:\n\u001b[0;32m---> 36\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths])\n\u001b[1;32m     37\u001b[0m     image_tensors \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mget_image\u001b[0;34m(image_path, image_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image\u001b[39m(image_path,image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./wikiart/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not loaded: ./wikiart/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7e8191d8c460>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:769\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for image_paths, labels in train_bar:\n",
    "        image_tensors = torch.stack([get_image(image_path) for image_path in image_paths])\n",
    "        images = image_tensors.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    wandb.log({\"epoch\": epoch+1, \"train_loss\": avg_train_loss})\n",
    "    \n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        for image_paths, labels in val_bar:\n",
    "            image_tensors = torch.stack([get_image(image_path) for image_path in image_paths])\n",
    "            image_tensors = image_tensors.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            outputs = model(image_tensors)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.argmax(dim=1)).sum().item()\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    wandb.log({\"val_loss\": avg_val_loss, \"val_accuracy\": val_accuracy})\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    if(epoch%5==0):\n",
    "        torch.save(model.state_dict(), f\"effnet_rcnn_epoch_{epoch+1}_genre.pth\")\n",
    "        torch.save(optimizer.state_dict(), f\"effnet_rcnn_optimizer_epoch_{epoch+1}_genre.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
